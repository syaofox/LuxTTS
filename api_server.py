"""
LuxTTS Legado API æœåŠ¡

ä¾› Legado ç­‰é˜…è¯»è½¯ä»¶é€šè¿‡ httpTTS é…ç½®è°ƒç”¨çš„ TTS æ¥å£ã€‚
å¯åŠ¨: LUXTTS_REF_AUDIO=ref_audio/äº¬äº¬.wav uvicorn api_server:app --host 0.0.0.0 --port 8765
æ³¨æ„: ä½¿ç”¨ workers=1 é¿å…å¤šè¿›ç¨‹é‡å¤åŠ è½½æ¨¡å‹ã€‚
"""

import gc
import io
import os
import random
import warnings
from pathlib import Path

import numpy as np
import torch
from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.responses import Response

# æŠ‘åˆ¶ torch ç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", message=".*torch.cuda.amp.autocast.*")

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆapi_server.py æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼‰
PROJECT_ROOT = Path(__file__).resolve().parent

# å…¨å±€æ¨¡å‹çŠ¶æ€
lux_tts = None
active_device = None

# é»˜è®¤å‚è€ƒéŸ³é¢‘ï¼ˆç¯å¢ƒå˜é‡ LUXTTS_REF_AUDIO æˆ–å¯åŠ¨æ—¶è®¾ç½®ï¼‰
DEFAULT_REF_AUDIO: str | None = os.environ.get("LUXTTS_REF_AUDIO")

# å‚è€ƒéŸ³é¢‘ encode_prompt ç¼“å­˜ï¼Œé¿å…ç›¸åŒå‚è€ƒéŸ³é¢‘é‡å¤è¯†åˆ«
_ENCODED_PROMPT_CACHE: dict[tuple, dict] = {}
_CACHE_MAX_SIZE = 10

app = FastAPI(
    title="LuxTTS API",
    description="Legado å…¼å®¹çš„ TTS æ¥å£ï¼ŒåŸºäº LuxTTS è¯­éŸ³å…‹éš†",
    version="0.1.0",
)


def _load_model(target_device: str):
    """åŠ è½½ LuxTTS æ¨¡å‹"""
    global lux_tts, active_device

    if lux_tts is not None and active_device == target_device:
        return lux_tts

    if target_device == "cuda" and not torch.cuda.is_available():
        raise ValueError("æœ¬ç³»ç»Ÿä¸æ”¯æŒ CUDA (GPU)ï¼Œè¯·ä½¿ç”¨ CPUã€‚")

    print(f"\nğŸ”„ Loading LuxTTS Model on [{target_device.upper()}]...")

    if lux_tts is not None:
        del lux_tts
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    try:
        from zipvoice.luxvoice import LuxTTS

        lux_tts = LuxTTS(device=target_device)
        active_device = target_device
        globals()["lux_tts"] = lux_tts
        print(f"âœ… Model successfully loaded on {target_device}")
        return lux_tts
    except Exception as e:
        print(f"Initialization Error: {e}")
        raise ValueError(f"åœ¨ {target_device} ä¸ŠåŠ è½½æ¨¡å‹å¤±è´¥: {e}") from e


def _resolve_ref_audio_path(path: str) -> Path:
    """è§£æå¹¶æ ¡éªŒå‚è€ƒéŸ³é¢‘è·¯å¾„ï¼Œé˜²æ­¢è·¯å¾„éå†"""
    if ".." in path:
        raise ValueError("è·¯å¾„ä¸å…è®¸åŒ…å« ..")

    if Path(path).is_absolute():
        resolved = Path(path).resolve()
    else:
        resolved = (PROJECT_ROOT / path).resolve()
        if not str(resolved).startswith(str(PROJECT_ROOT)):
            raise ValueError(f"å‚è€ƒéŸ³é¢‘è·¯å¾„è¶…å‡ºé¡¹ç›®èŒƒå›´: {path}")

    if not resolved.exists():
        raise ValueError(f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    if not resolved.is_file():
        raise ValueError(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {path}")
    return resolved


def _get_encoded_prompt(model, ref_path: Path, duration: int = 5, rms: float = 0.01) -> dict:
    """è·å–å‚è€ƒéŸ³é¢‘çš„ç¼–ç ç»“æœï¼Œç›¸åŒæ–‡ä»¶å¤ç”¨ç¼“å­˜"""
    mtime = ref_path.stat().st_mtime
    key = (str(ref_path.resolve()), duration, rms, mtime)
    if key in _ENCODED_PROMPT_CACHE:
        return _ENCODED_PROMPT_CACHE[key]
    encoded = model.encode_prompt(str(ref_path), duration=duration, rms=rms)
    if len(_ENCODED_PROMPT_CACHE) >= _CACHE_MAX_SIZE:
        _ENCODED_PROMPT_CACHE.clear()
    _ENCODED_PROMPT_CACHE[key] = encoded
    return encoded


def _set_random_seed():
    """è®¾ç½®éšæœºç§å­ä¸ºéšæœºå€¼ï¼Œä¿è¯æ¯æ¬¡æ¨ç†ç»“æœä¸åŒ"""
    seed = random.randint(0, 2**32 - 1)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    return seed


def _generate_tts(text: str, ref_audio_path: str, speed: float = 0.8) -> bytes:
    """ç”Ÿæˆ TTS éŸ³é¢‘å¹¶è¿”å› WAV å­—èŠ‚ã€‚å‚æ•°ä¸ UI ä¸€è‡´ï¼šrms=0.01, steps=4, t_shift=0.9, ref_duration=5, ç§å­éšæœº"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = _load_model(device)

    _set_random_seed()

    ref_path = _resolve_ref_audio_path(ref_audio_path)
    encoded_prompt = _get_encoded_prompt(model, ref_path, duration=5, rms=0.01)

    final_wav = model.generate_speech(
        text,
        encoded_prompt,
        num_steps=4,
        t_shift=0.9,
        speed=speed,
        return_smooth=False,
    )

    audio_data = final_wav.detach().cpu().numpy().squeeze()
    audio_data = np.clip(audio_data, -1.0, 1.0)
    audio_data = (audio_data * 32767).astype(np.int16)

    # Legado åˆå¹¶éŸ³é¢‘æ—¶ä¼šåæ‰è¾¹ç•Œæ ·æœ¬ï¼Œåœ¨å¤´å°¾æ·»åŠ é™éŸ³ padding ä½œä¸ºç¼“å†²
    SAMPLE_RATE = 48000
    PAD_MS = 80  # æ¯ä¾§ 80ms é™éŸ³ï¼Œåˆå¹¶æ—¶è¢«æˆªæ‰çš„æ˜¯é™éŸ³è€Œéè¯­éŸ³
    pad_samples = int(SAMPLE_RATE * PAD_MS / 1000)
    pad = np.zeros(pad_samples, dtype=np.int16)
    audio_data = np.concatenate([pad, audio_data, pad])

    # å†™å…¥ WAV åˆ°å†…å­˜
    import wave

    buffer = io.BytesIO()
    with wave.open(buffer, "wb") as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(2)  # 16-bit
        wav_file.setframerate(48000)
        wav_file.writeframes(audio_data.tobytes())

    return buffer.getvalue()


def _get_ref_audio(ref_audio: str | None) -> str:
    """è·å–æœ‰æ•ˆçš„å‚è€ƒéŸ³é¢‘è·¯å¾„"""
    path = ref_audio or DEFAULT_REF_AUDIO
    if not path:
        raise HTTPException(
            status_code=400,
            detail="æœªé…ç½®å‚è€ƒéŸ³é¢‘ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ LUXTTS_REF_AUDIO æˆ–åœ¨è¯·æ±‚ä¸­ä¼ å…¥ ref_audio å‚æ•°ã€‚",
        )
    return path


@app.get("/api/tts")
async def tts_get(
    text: str = Query(..., description="å¾…åˆæˆæ–‡æœ¬"),
    speed: float = Query(0.8, ge=0.1, le=3.0, description="è¯­é€Ÿ"),
    ref_audio: str | None = Query(None, description="å‚è€ƒéŸ³é¢‘è·¯å¾„"),
):
    """GET æ–¹å¼ TTS æ¥å£ï¼ŒLegado å…¼å®¹"""
    ref_path = _get_ref_audio(ref_audio)
    try:
        wav_bytes = _generate_tts(text, ref_path, speed)
        return Response(content=wav_bytes, media_type="audio/wav")
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e)) from e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)) from e


@app.post("/api/tts")
async def tts_post(request: Request):
    """POST æ–¹å¼ TTS æ¥å£ï¼Œæ”¯æŒ JSON å’Œ form-urlencodedï¼ŒLegado å…¼å®¹"""
    content_type = request.headers.get("content-type", "")

    if "application/json" in content_type:
        body = await request.json()
        text = body.get("text")
        speed = float(body.get("speed", 0.8))
        ref_audio = body.get("ref_audio")
    else:
        # form-urlencoded
        form = await request.form()
        text = form.get("text")
        speed_val = form.get("speed", "0.8")
        speed = float(speed_val) if speed_val else 0.8
        ref_audio = form.get("ref_audio")

    if not text:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ text å‚æ•°")

    ref_path = _get_ref_audio(ref_audio)
    try:
        wav_bytes = _generate_tts(text, ref_path, speed)
        return Response(content=wav_bytes, media_type="audio/wav")
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e)) from e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)) from e


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "service": "LuxTTS API"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8765,
        workers=1,
    )
